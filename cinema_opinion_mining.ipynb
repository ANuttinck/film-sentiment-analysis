{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authors: Alexandre Gramfort\n",
    "#          Chloe Clavel\n",
    "# License: BSD Style.\n",
    "# TP Cours ML Telecom ParisTech MDI343\n",
    "\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.cross_validation import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "# Chargment des données\n",
    "\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "stopwords = open(op.join('data','english.stop')).read().split('\\n')\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation du classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition de la fonction cleanText (question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# La definition de la fonction cleanText a ete deplacee ici\n",
    "# pour inclure l'option del_stopwords a la fonction count_words\n",
    "\n",
    "# La fonction cleanText retire les stopwords contenu dans le fichier english.stop\n",
    "# des textes contenus dans la liste rawTxt ainsi que la regex '\\n'\n",
    "\n",
    "def cleanText(rawTxt):\n",
    "    cleanTxt = ' '.join(filter(lambda x: x.lower() not in stopwords,\n",
    "                               rawTxt.split()))\n",
    "    \n",
    "    return cleanTxt.replace('\\n', '')  # .replace(r'\\W', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(texts, del_stopwords):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    \n",
    "    if del_stopwords:\n",
    "        # cette partie a ete ajoute pour la question 5\n",
    "        cleanedTexts = list(map(cleanText, texts))\n",
    "    else:\n",
    "        cleanedTexts = texts\n",
    "  \n",
    "    words = set(' '.join(cleanedTexts).split())\n",
    "    vocabulary = {k: i for i, k in enumerate(words)} \n",
    "    n_features = len(words)\n",
    "    counts = np.zeros((len(cleanedTexts), n_features))\n",
    "\n",
    "    for l, text in enumerate(cleanedTexts):\n",
    "        for wd in text.split():\n",
    "            counts[l, vocabulary[wd]] += 1\n",
    "\n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes positives et négatives ont été assignées à l'aide d'un classifieur qui tente de reconnaître les notes attribuées par les auteurs des commentaires.  \n",
    "Etant donnée la diversité des systèmes de notations utilisés par les auteurs des commentaires, le label des commentaires (positif ou negatif) a été attribué à partir de la  de la manière suivante :\n",
    "\n",
    "- Les notes (numérique ou sous forme d'étoiles) doivent préciser l'échelle de notation :\n",
    "    Ex : \"8/10\", \"four out of five\", and \"OUT OF ****: ***\"\n",
    "\n",
    "- Pour un système de notation à 5 étoiles (et les système numériques compatibles) :\n",
    "    Les notes de 3,5 étoiles et plus sont considérées comme positives\n",
    "    Les notes de 2 étoiles et moins sont considérées comme négatives\n",
    "\n",
    "- Pour un système de notation à 4 étoiles (et les système numériques compatibles) :\n",
    "    Les notes de 3 étoiles et plus sont considérées comme positives\n",
    "    Les notes de 1,5 étoiles et moins sont considérées comme négatives\n",
    "\n",
    "- Pour un système de notation avec des lettres:\n",
    "\tLes notes à partir de B sont considérées comme postives\n",
    "\tLes notes jusqu'à C- sont considérée comme négatives\n",
    "\n",
    "De cette manière, l'algorythme n'est entrainé (et testé) qu'à partir de commentaire associés à des notes extrêmes (très basses ou très hautes). Les commentaires associés à des notes autour de la moyenne ont été exclus de la base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self):\n",
    "        pass\n",
    "  \n",
    "    def fit(self, X, y):\n",
    "        self.labels = np.array([(i, k) for i, k\n",
    "                                in enumerate(set(y))], \n",
    "                          dtype=[('index', np.int),\n",
    "                                 ('label', np.int)])\n",
    "        # labels permets de distinguer les indices\n",
    "        # (compris entre 0 et le nb de labels-1)\n",
    "        # et les labels de y \n",
    "        # (qui pourrait être {-1, 1} ou encore {5, 9, 70})\n",
    "        # il doivent seulement être des int\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        self.prior = np.empty(len(self.labels))\n",
    "        self.condprob = np.empty((len(self.labels), X.shape[1]))\n",
    "\n",
    "        for c in self.labels:\n",
    "            nC = y[y==c['label']].shape[0]\n",
    "            self.prior[c['index']] = nC / n\n",
    "            T = np.sum(X[y==c['label']], axis=0)\n",
    "            self.condprob[c['index']] = (T + 1) / np.sum(T + 1)\n",
    "    \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        score = np.empty((X.shape[0], len(self.labels)))\n",
    "        score[:,:] = np.log(self.prior)\n",
    "\n",
    "        for nzR, nzC in np.transpose(np.nonzero(X)):\n",
    "            score[nzR] += np.log(self.condprob.T[nzC])\n",
    "\n",
    "        # la fonction predict renvoie les labels tels qu'ils étaient\n",
    "        # dans l'argument y de la fonction fit\n",
    "        return self.labels[np.argmax(score, axis=1)]['label']\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comptage des mots dans les textes bruts\n",
    "vocabulary, X = count_words(texts, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 99.60%\n",
      "Test score : 83.60%\n"
     ]
    }
   ],
   "source": [
    "# Test sur la moitie des commentaires de l'algorithme Naive Bayes\n",
    "# implemente et entraine sur l'autre moitie des donnees\n",
    "\n",
    "nb = NB()\n",
    "nb.fit(X[::2], y[::2])\n",
    "print(\"Training score : {:.2%}\".format(nb.score(X[::2], y[::2])))\n",
    "print(\"Test score : {:.2%}\".format(nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee du classifieur Naive Bayes implemente (a partir des textes bruts): 0: 79.50%\n",
      "1: 85.25%\n",
      "2: 81.25%\n",
      "3: 81.25%\n",
      "4: 80.75% \n",
      "IC de l'accuracy : 81.60%% +/- 1.9339%\n",
      "1 loop, best of 1: 14.2 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Calcul des K-Folds sur le text brut :\n",
    "# implémentation à partir de la fonction KFolds de sklearn (v17.)\n",
    "\n",
    "kf = KFold(X.shape[0], n_folds=5, shuffle=True)\n",
    "kFoldsRes = []\n",
    "for train_indices, test_indices in kf:\n",
    "\n",
    "    train_X = X[train_indices, :]\n",
    "    train_y = y[train_indices]\n",
    "    test_X = X[test_indices, :]\n",
    "    test_y = y[test_indices]\n",
    "\n",
    "    nbk = NB()\n",
    "    nbk.fit(train_X, train_y)\n",
    "    kFoldsRes.append(nbk.score(test_X, test_y))\n",
    "\n",
    "print(\"Scores de la validation croisee du classifieur Naive Bayes implemente\",\n",
    "      \"(a partir des textes bruts):\",\n",
    "      \"\\n\".join('{}: {:.2%}'.format(*k) for k in enumerate(kFoldsRes)),\n",
    "      \"\\nIC de l'accuracy : {0:.2%}% +/- {1:.4%}\".format(\n",
    "        np.mean(kFoldsRes),\n",
    "        np.std(kFoldsRes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee du classifieur Naive Bayes implemente (a partir des textes bruts):\n",
      " 0: 81.50%\n",
      "1: 82.50%\n",
      "2: 83.25%\n",
      "3: 81.25%\n",
      "4: 81.75% \n",
      " IC de l'accuracy : 82.05% +/- 0.7314%\n",
      "1 loop, best of 1: 15.8 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Calcul des K-Folds sur les textes bruts :\n",
    "# à partir des fonctions KFolds et cross_val_score de sklearn (v17.)\n",
    "\n",
    "kf = KFold(len(X), n_folds=5, shuffle=True)\n",
    "cl_scores = cross_val_score(nb, X, y, cv=kf)\n",
    "print(\"Scores de la validation croisee du classifieur Naive Bayes implemente\",\n",
    "      \"(a partir des textes bruts):\\n\",\n",
    "      \"\\n\".join('{}: {:.2%}'.format(*k) for k in enumerate(cl_scores)),\n",
    "      \"\\n IC de l'accuracy : {0:.2%} +/- {1:.4%}\".format(\n",
    "        np.mean(cl_scores),\n",
    "        np.std(cl_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux dernieres cellules ont exactement le meme objectif :  \n",
    "evaluer l'algorithme du Naive Bayes sur la problématique de sentiment analysis à partir des commentaires de films  \n",
    "  \n",
    "De plus, ils utilisent exactement la même méthode :  \n",
    "une validation croisee sur 5 tirages.  \n",
    "  \n",
    "La premiere a ete implementee uniquement a partir de la fonction KFold de sklearn alors que la deuxieme utilise la fonction cross_val_score. On verifie qu'on obtient des résultats et des temps d'execution très similaires (qui varient faiblement du fait du shuffle aleatoire). Ce shuffle garantit que chacun des folds soit equilibre entre les avis positifs et les avis negatifs. Pour la suite nous utiliserons, pour des questions pratiques, la fonction cross_val_score de sklearn.    \n",
    "  \n",
    "On obtient ainsi une classification correcte à plus de 80% à partir des commentaires bruts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee du classifieur Naive Bayes implemente (a partir des textes sans stop words):\n",
      " 0: 78.75%\n",
      "1: 83.00%\n",
      "2: 82.00%\n",
      "3: 81.25%\n",
      "4: 83.25% \n",
      " IC de l'accuracy : 81.65% +/- 1.6171%\n",
      "1 loop, best of 1: 38.8 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Comptage des mots dans les documenst nettoyes\n",
    "# a l'aide la fonction cleanText\n",
    "cl_vocabulary, cl_X = count_words(texts, True)\n",
    "\n",
    "# Cross-validation du classifieur Naive Bayes implemente\n",
    "kf = KFold(len(X), n_folds=5, shuffle=True)\n",
    "cl_scores = cross_val_score(nb, X, y, cv=kf)\n",
    "\n",
    "print(\"Scores de la validation croisee du classifieur Naive Bayes implemente\",\n",
    "      \"(a partir des textes sans stop words):\\n\",\n",
    "      \"\\n\".join('{}: {:.2%}'.format(*k) for k in enumerate(cl_scores)),\n",
    "      \"\\n IC de l'accuracy : {0:.2%} +/- {1:.4%}\".format(\n",
    "        np.mean(cl_scores),\n",
    "        np.std(cl_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les resultats ci-dessus sont obtenus a partir des commentaires pretraites avec la fonction implementee cleanText qui retirent les stop words (listes dans le fichier 'english.stop') des commentaires de films ainsi que la regex '\\n'.  \n",
    "  \n",
    "On peut en effet, penser que ces mots courants sont utilises indifferemment dans des commentaires positifs et des des commentaires negatifs. Ils n'apportent donc logiquement aucune information sur l'avis de l'auteur du commentaire par rapport au film. En les retirant, on espere diminuer l'eventuel bruit qu'il generait et permettre a l'algoritme de se concentrer sur les autres mots.  \n",
    "Je me suis permis de supprimer egalement la regex '\\n' des commentaires afin que les mots qui y sont accoles puissent etre reunis avec les eventuelles autres occurences de ce mot. Ainsi, \"\\ndamn\" est compte comme une occurence du mot \"damn\". L'ensemble des autres caracteres sont conserves.    \n",
    "  \n",
    "En conclusion, on constate que, sur 5 tirages aleatoires, l'amelioration du score de l'algorithme de Naive Bayes est très faible. Les stop words produisaient un bruit quasiment negligeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# La fonction display_CVResults sera utilisee pour les prochaines questions\n",
    "# afin d'afficher les scores d'une validation croisee\n",
    "# pour differents modeles sur les commentaires\n",
    "# (qui ont subit des pretraitements differents)\n",
    "def display_CVResults(model, texts, nb_folds):\n",
    "    kf = KFold(len(X), n_folds=nb_folds, shuffle=True)\n",
    "    cv_NBscores = cross_val_score(model, texts, y, cv=kf)\n",
    "    \n",
    "    print(\"Scores de la validation croisee :\\n\",\n",
    "          \"\\n\".join('{}: {:.2%}'.format(*k) for k in enumerate(cv_NBscores)),\n",
    "          \"\\n IC de l'accuracy : {0:.2%} +/- {1:.4%}\".format(\n",
    "            np.mean(cv_NBscores),\n",
    "            np.std(cv_NBscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee :\n",
      " 0: 81.00%\n",
      "1: 84.00%\n",
      "2: 81.50%\n",
      "3: 78.75%\n",
      "4: 77.50% \n",
      " IC de l'accuracy : 80.55% +/- 2.2605%\n",
      "1 loop, best of 1: 12 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Cross-validation du classifieur Naive Bayes de sklearn\n",
    "# a partir des textes pretraites avec la classe CountVectorizer()\n",
    "# les stop words sont ceux de la classe CountVectorizer()\n",
    "# les features sont les mots contenus dans les commentaires\n",
    "\n",
    "NB_model = Pipeline([\n",
    "        ('cntVect', CountVectorizer(stop_words={'english'})),\n",
    "        ('nbCl', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "display_CVResults(NB_model, texts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant les classes CountVectorizer et MultinomialNB de sklearn, les scores restent proches de 80%.  \n",
    "Comme on peut le constater, l'algorithme implemente dans sklearn est plus rapide mais permet d'obtenir des resultats très similaires à ceux de la classe NB.\n",
    "    \n",
    "Les petites differences entre les scores sont majoritairement dues aux options de la classe CountVectorizer. Par defaut, la classe CountVectorizer ne tient pas compte de la ponctuation et les features sont les mots (au sens de la regex '\\w'). Au contraire, la fonction implementee count_words considere un mot comme une chaine de caractere separee par un espace. La premiere definition pose pose differents problemes :\n",
    "- elle considere les mots avec des tirets comme 2 mots differents alors qu'on peut considerer que la connotation (positive ou negative) decoule de leur association\n",
    "- elle ne prend pas en compte la ponctuation qui peut apporter des informations sur l'avis de l'auteur du commentaire (ex : \"???\", \"!!!!\", \":S\")  \n",
    "  \n",
    "Cependant, la seconde methode presente egalement des inconvenients puisqu'en tenant compte de la ponctuation, elle differencie par exemple \"mot.\" de \"mot\".  \n",
    "  \n",
    "Empiriquement, la fonction implementee semble capables d'atteindre des scores légèrement superieurs et plus stable (par rapport a leur ecart-type). Pour d'avantage, de details, voir la partie \"Analyse et test sur les methodes de vectorisation\" à la fin de ce notebook.  \n",
    "  \n",
    "On remarque qu'on utilise desormais l'option \"stop_words={'english'}\" pour retirer les stop words. La difference avec l'option  \"stop_words=stopwords\" est cependant negligeable et n'a pas de réelle influence sur le score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee :\n",
      " 0: 84.75%\n",
      "1: 82.25%\n",
      "2: 84.25%\n",
      "3: 83.25%\n",
      "4: 82.00% \n",
      " IC de l'accuracy : 83.30% +/- 1.0770%\n",
      "1 loop, best of 1: 48.4 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Cross-validation du classifieur Naive Bayes de sklearn\n",
    "# a partir des textes pretraites avec la classe CountVectorizer()\n",
    "# les stop words sont ceux de la classe CountVectorizer()\n",
    "# les features sont les caracteres contenus dans les commentaires\n",
    "\n",
    "NB_model = Pipeline([\n",
    "        ('cntVect', CountVectorizer(stop_words={'english'},\n",
    "                                    ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b',\n",
    "                                    min_df=1)),\n",
    "        ('nbCl', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "display_CVResults(NB_model, texts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La creation de la matrice des variables explicatives en utilisant les bigrammes permet de prendre en compte les associations de mots (par pair). En effet, avec le code précédent, les variables explicatives comprennent les mots individuellement mais aussi les pairs de mots qui se suivent dans une phrase. Le modèle tient donc compte des associations d'idées et permet d'isoler des expressions. Dans les faits, ce prétraitement a un impact positif sur les scores. On peut cependant deplorer la multiplication du nombre de variables explicatives qui rend la matrice encore plus sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee :\n",
      " 0: 62.50%\n",
      "1: 59.75%\n",
      "2: 61.50%\n",
      "3: 62.25%\n",
      "4: 60.00% \n",
      " IC de l'accuracy : 61.20% +/- 1.1336%\n",
      "1 loop, best of 1: 37.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Cross-validation du classifieur Naive Bayes de sklearn\n",
    "# a partir des textes pretraites avec la classe CountVectorizer()\n",
    "# les stop words sont ceux de la classe CountVectorizer()\n",
    "# les features sont les caracteres contenus dans les commentaires\n",
    "\n",
    "NB_model = Pipeline([\n",
    "        ('cntVect', CountVectorizer(stop_words={'english'},\n",
    "                                    analyzer='char')),\n",
    "        ('nbCl', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "display_CVResults(NB_model, texts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec l'option \"analyzer='char'\", CountVectorizer construit une matrice ou les features sont des caracteres. L'algorithme du Naive Bayes estiment donc empiriqument les probabilites qu'un caractere se trouve dans un commentaire sachant que celui est positif ou negatif. Il estime ensuite la probabilite que les commentaires soient positifs ou negatifs en fonction des caracteres qu'ils contiennent pour la comparer avec les probabilites a priori.  \n",
    "Or la relation entre l'avis d'une personne sur un film et l'ocurrence des caracteres dans son commentaire semble ne pas etre fondee. On observe en effet, que cette strategie ne permet de classifier les commentaires correctement que dans 60% des cas. De plus, son accuracy semble plus eleve que lorsqu'on utilise les mots. Le fait que ce classifieur soit un peu plus efficace que le hasard (qui correspondrait à un score de 50%) peut, à mon sens, s'expliquer par le fait que certains caracteres speciaux puissent être d'avantage associe a un type de commentaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee :\n",
      " 0: 85.50%\n",
      "1: 86.25%\n",
      "2: 82.50%\n",
      "3: 86.50%\n",
      "4: 83.50% \n",
      " IC de l'accuracy : 84.85% +/- 1.5780%\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation d'une Regression Logistique de sklearn\n",
    "# a partir des textes pretraites avec la classe CountVectorizer()\n",
    "# les stop words sont ceux de la classe CountVectorizer()\n",
    "\n",
    "LR_model = Pipeline([\n",
    "        ('cntVect', CountVectorizer(stop_words={'english'},\n",
    "                                    ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b',\n",
    "                                    min_df=1)),\n",
    "        ('lrCl', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "display_CVResults(LR_model, texts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regression logistique (avec une penalisation quadratique et un intercep) permet d'atteindre un score légèrement superieur au classifieur du Naive Bayes. Ces deux algorirhmes sont adaptes pour une premiere approche du text mining.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee :\n",
      " 0: 83.25%\n",
      "1: 86.50%\n",
      "2: 85.25%\n",
      "3: 86.25%\n",
      "4: 83.50% \n",
      " IC de l'accuracy : 84.95% +/- 1.3546%\n"
     ]
    }
   ],
   "source": [
    "# pretraitement des textes :\n",
    "# on remplace chaque mot par sa racine\n",
    "# grace à la fonction stem de la classe SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "st_texts = [\" \".join([stemmer.stem(word) for word\n",
    "                      in sentence.split()]) for sentence in texts]\n",
    "# Apres de nombreux test la fonction map ne permet pas de réaliser\n",
    "# cette tâche plus rapidement\n",
    "\n",
    "# Cross-validation de la Regression Logistique de sklearn\n",
    "# a partir des text pretraites obtenus\n",
    "display_CVResults(LR_model, st_texts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction stem de la classe SnowballStemmer permet de trouver la racine des mots dictionnaire (anglais dans notre cas). Cette fonction est utilisee ici pour regrouper les mots par rapport à leur racine afin de reduire le nombre de mots differents (et donc le nombre de features). On espere ainsi affiner les probabilites que Naive Bayes associe a chaque \"racine\" et ainsi ameliorer ses predictions. Dans les faits, on observe que l'utilisation de cette methode permet une amelioration des predictions bien que celle-ci soit relativement limitee. Cette technique permet d'extraire l'information liee au fond du commentaire, leur contexte et leur forme ne sont cependant pas ideals pour ce genre de methode (language familier, nombreuses fautes de langue, fautes de frappe, codes, ...).  \n",
    "L'accuracy est proche de 85% et semble plus stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# /!\\ L'utilisation de nltk a nécéssité une installation\n",
    "# de nltk 3.2.1 via 'conda update'\n",
    "# Une erreur se produit pour la fonction pos_tag()\n",
    "# avec la version 3.2.0 \n",
    "# (obtenue avec la commande \"nltk.download('all')\")\n",
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de la validation croisee :\n",
      " 0: 86.50%\n",
      "1: 86.00%\n",
      "2: 84.25%\n",
      "3: 84.75%\n",
      "4: 84.00% \n",
      " IC de l'accuracy : 85.10% +/- 0.9823%\n"
     ]
    }
   ],
   "source": [
    "# liste des codes pour les noms, verbes et adjectifs\n",
    "NVAD = ['NN', 'JJ', 'JJR', 'JJS', 'NN',\n",
    "        'NNP', 'NNS', 'NNPS', 'RB', 'RBR',\n",
    "        'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "pos_texts = [\" \".join([word[0] for word\n",
    "                       in pos_tag(word_tokenize(sentence))\n",
    "                       if (word[1] in NVAD)]) for sentence in texts]\n",
    "\n",
    "display_CVResults(LR_model, pos_texts, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse et test sur les methodes de vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de features avec CountVectorizer() : 73 \n",
      "Nombre de features avec count_words : 50375 \n",
      "Nombre de mots différents approximatifs : 50336\n"
     ]
    }
   ],
   "source": [
    "wd_CntVect = CountVectorizer(stop_words={'english'}, analyzer='char')\n",
    "\n",
    "cl_vocabulary, cl_X = count_words(texts, True)\n",
    "wd_CntVect.fit(texts)\n",
    "\n",
    "diff = list(set(cl_vocabulary.keys()) - set(wd_CntVect.get_feature_names()))\n",
    "\n",
    "print(\"\\nNombre de features avec CountVectorizer() :\",\n",
    "      len(wd_CntVect.get_feature_names()),\n",
    "      \"\\nNombre de features avec count_words :\",\n",
    "      len(set(cl_vocabulary.keys())),\n",
    "      \"\\nNombre de mots différents approximatifs :\",\n",
    "      len(diff))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x05', '\\x12', '\\x13', '\\x14', '\\x16', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "char_CntVect = CountVectorizer(stop_words={'english'}, analyzer='char')\n",
    "res = char_CntVect.fit_transform(texts)\n",
    "print(char_CntVect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     2     33      7      7     12 705709   1056   9120     26    109\n",
      "      36    192  15345   5650   5742    670     63  35269   9670  32162\n",
      "     470   1529   1560    630    397    336    376    290    330    484\n",
      "    1268   1540    876    240     18   2201     12     44      3     44\n",
      "       3    573    220 223499  46694  83606  95302 338479  62165  60172\n",
      "  150770 209470   7172  25390 126738  76512 190446 207447  52282   2562\n",
      "  162031 193348 256611  76181  32849  51563   5032  55447   2918      0\n",
      "       0      0      1]] [[     4     11      0      0      0 787106    657   8492     29    112\n",
      "      23    117  15280   6014   6039    384     95  42448  10070  33714\n",
      "     515   1399   1728    678    408    313    422    296    485    451\n",
      "    1486   1502    974    319     25   1570      5     46      8     46\n",
      "       2    495    277 257030  50316  96508 106545 384360  73883  67057\n",
      "  169969 241671   7611  26962 143817  87534 216771 229597  57059   3180\n",
      "  188651 222104 287907  83403  36258  57276   5758  61904   3318      1\n",
      "       5      1      3]]\n"
     ]
    }
   ],
   "source": [
    "print(res[:1000,:].sum(axis=0), res[1000:,:].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
